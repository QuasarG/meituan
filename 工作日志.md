# 工作日志
## 4.11
1. rider_information去重
2. `merge.py` 实现合并三个数据表，每一行代表一个骑手在某一天的表现，以及这一天的天气状态（189816行）
    合并为`merged_data.csv`
3. 重新运行了骑手聚类，结果为`cluster_analysis_rider.csv`，此时最佳聚类数为3
4. 对天气数据进行预处理，因为对同一天出现了不同的数据，选取该天对应字段出现最多的为正确值
    使用`duplicate_weather.py`进行了去重，输出为`data\processed_data\duplicated_weather.csv`
5. 删除`merged_data.csv`，重新运行`merge.py`，输出为`merged_data.csv`
6. 去除`merge.py`中对于只在某一个表中出现的处理进行优化。想要的仅仅是找出两个表格里面是否有单独出现的骑手，也就是无法匹配的情况，这种数据无法进行分析，需要删除，但是结果显示只在骑手信息表中存在的骑手ID数量: 0，只在行为数据表中存在的骑手ID数量: 0，是不是说所有的骑手在两个表格里都是相互匹配的？只是有空值？这一段处理有些模糊，进行修改，如果确实是对应好了的，那么生成info_only和behavior_only两个文件就没必要了
7. 生成消息显示不重复骑手id数量3276，直接分别读取两个骑手原始数据检测不重复id数量为3276，数据吻合。
8. 检查合并生成的数据是否吻合：
    骑手信息表中不重复的骑手ID数量: 3276
    行为数据表中不重复的骑手ID数量: 3276
    合并数据表中不重复的骑手ID数量: 3276
    吻合。

## 4.12
1. 发现rider_information表有3604行，中存在重复的骑手id，需要进行合并
    成功去重，目前rider_information表中不重复的骑手ID数量: 3276
2. 好像忘了把新的天气替换原来的天气了，需要把duplicated_weather.csv替换掉原来的weather.csv
    重新合并后，出现57587条记录
3. 突然想到rider_daily_behavior表中也有有可能出现同一id同一天出现不同状况的可能，进行一下检查`deduplicated_rider_behavior.py`
    检查结果显示无重复，但是不放心，需要进行验证（57587 = 骑手id数 * 每个人工作天数）
    去重后数据总行数: 57587
    不重复骑手ID数量: 3276
    所有骑手工作天数总和: 57587
    验证结果: 通过
4. 重新合并，目前merged_data.csv中共有57587行，数据吻合，按id排序，每一个id的日期是升序连续的
---
5. 进行缺失值统计，缺失超过50%的列不做考虑